<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />




<title>euro-hub-ensemble-draft.knit.md</title>

<script src="site_libs/header-attrs-2.11/header-attrs.js"></script>
<script src="site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/cosmo.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/textmate.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>

<link rel="icon" href="https://github.com/workflowr/workflowr-assets/raw/master/img/reproducible.png">
<!-- Add a small amount of space between sections. -->
<style type="text/css">
div.section {
  padding-top: 12px;
}
</style>



<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>




<style type="text/css">
/* for pandoc --citeproc since 2.11 */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>




<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.tab('show');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">European Covid-19 Forecast Hub: Ensembles</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Home</a>
</li>
<li>
  <a href="euro-hub-ensemble-draft.html">Read</a>
</li>
<li>
  <a href="https://docs.google.com/document/d/1XT7xwljCfaQ1_CpKxyJySqiPsIZ2bWNWFJE_v_U6EHc/edit">Edit text</a>
</li>
<li>
  <a href="https://github.com/kathsherratt/euro-hub-ensemble/blob/main/analysis/euro-hub-ensemble-draft.Rmd">Edit code</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">



<h1 class="title toc-ignore">Predictive performance of multi-model ensemble forecasts of Covid-19 across European nations</h1>

</div>


<p>View draft: <a href="https://covid19-forecast-hub-europe.github.io/euro-hub-ensemble/euro-hub-ensemble-draft.html">Rendered</a> | <a href="https://docs.google.com/document/d/1XT7xwljCfaQ1_CpKxyJySqiPsIZ2bWNWFJE_v_U6EHc/edit">Google doc</a></p>
<p>
<button type="button" class="btn btn-default btn-workflowr btn-workflowr-report" data-toggle="collapse" data-target="#workflowr-report">
<span class="glyphicon glyphicon-list" aria-hidden="true"></span> workflowr <span class="glyphicon glyphicon-ok text-success" aria-hidden="true"></span>
</button>
</p>
<div id="workflowr-report" class="collapse">
<ul class="nav nav-tabs">
<li class="active">
<a data-toggle="tab" href="#summary">Summary</a>
</li>
<li>
<a data-toggle="tab" href="#checks"> Checks <span class="glyphicon glyphicon-ok text-success" aria-hidden="true"></span> </a>
</li>
<li>
<a data-toggle="tab" href="#versions">Past versions</a>
</li>
</ul>
<div class="tab-content">
<div id="summary" class="tab-pane fade in active">
<p>
<strong>Last updated:</strong> 2022-01-10
</p>
<p>
<strong>Checks:</strong> <span class="glyphicon glyphicon-ok text-success" aria-hidden="true"></span> 7 <span class="glyphicon glyphicon-exclamation-sign text-danger" aria-hidden="true"></span> 0
</p>
<p>
<strong>Knit directory:</strong> <code>euro-hub-ensemble/</code> <span class="glyphicon glyphicon-question-sign" aria-hidden="true" title="This is the local directory in which the code in this file was executed."> </span>
</p>
<p>
This reproducible <a href="http://rmarkdown.rstudio.com">R Markdown</a> analysis was created with <a
  href="https://github.com/jdblischak/workflowr">workflowr</a> (version 1.6.2). The <em>Checks</em> tab describes the reproducibility checks that were applied when the results were created. The <em>Past versions</em> tab lists the development history.
</p>
<hr>
</div>
<div id="checks" class="tab-pane fade">
<div id="workflowr-checks" class="panel-group">
<div class="panel panel-default">
<div class="panel-heading">
<p class="panel-title">
<a data-toggle="collapse" data-parent="#workflowr-checks" href="#strongRMarkdownfilestronguptodate"> <span class="glyphicon glyphicon-ok text-success" aria-hidden="true"></span> <strong>R Markdown file:</strong> up-to-date </a>
</p>
</div>
<div id="strongRMarkdownfilestronguptodate" class="panel-collapse collapse">
<div class="panel-body">
<p>Great! Since the R Markdown file has been committed to the Git repository, you know the exact version of the code that produced these results.</p>
</div>
</div>
</div>
<div class="panel panel-default">
<div class="panel-heading">
<p class="panel-title">
<a data-toggle="collapse" data-parent="#workflowr-checks" href="#strongEnvironmentstrongempty"> <span class="glyphicon glyphicon-ok text-success" aria-hidden="true"></span> <strong>Environment:</strong> empty </a>
</p>
</div>
<div id="strongEnvironmentstrongempty" class="panel-collapse collapse">
<div class="panel-body">
<p>Great job! The global environment was empty. Objects defined in the global environment can affect the analysis in your R Markdown file in unknown ways. For reproduciblity it’s best to always run the code in an empty environment.</p>
</div>
</div>
</div>
<div class="panel panel-default">
<div class="panel-heading">
<p class="panel-title">
<a data-toggle="collapse" data-parent="#workflowr-checks" href="#strongSeedstrongcodesetseed20211126code"> <span class="glyphicon glyphicon-ok text-success" aria-hidden="true"></span> <strong>Seed:</strong> <code>set.seed(20211126)</code> </a>
</p>
</div>
<div id="strongSeedstrongcodesetseed20211126code" class="panel-collapse collapse">
<div class="panel-body">
<p>The command <code>set.seed(20211126)</code> was run prior to running the code in the R Markdown file. Setting a seed ensures that any results that rely on randomness, e.g. subsampling or permutations, are reproducible.</p>
</div>
</div>
</div>
<div class="panel panel-default">
<div class="panel-heading">
<p class="panel-title">
<a data-toggle="collapse" data-parent="#workflowr-checks" href="#strongSessioninformationstrongrecorded"> <span class="glyphicon glyphicon-ok text-success" aria-hidden="true"></span> <strong>Session information:</strong> recorded </a>
</p>
</div>
<div id="strongSessioninformationstrongrecorded" class="panel-collapse collapse">
<div class="panel-body">
<p>Great job! Recording the operating system, R version, and package versions is critical for reproducibility.</p>
</div>
</div>
</div>
<div class="panel panel-default">
<div class="panel-heading">
<p class="panel-title">
<a data-toggle="collapse" data-parent="#workflowr-checks" href="#strongCachestrongnone"> <span class="glyphicon glyphicon-ok text-success" aria-hidden="true"></span> <strong>Cache:</strong> none </a>
</p>
</div>
<div id="strongCachestrongnone" class="panel-collapse collapse">
<div class="panel-body">
<p>Nice! There were no cached chunks for this analysis, so you can be confident that you successfully produced the results during this run.</p>
</div>
</div>
</div>
<div class="panel panel-default">
<div class="panel-heading">
<p class="panel-title">
<a data-toggle="collapse" data-parent="#workflowr-checks" href="#strongFilepathsstrongrelative"> <span class="glyphicon glyphicon-ok text-success" aria-hidden="true"></span> <strong>File paths:</strong> relative </a>
</p>
</div>
<div id="strongFilepathsstrongrelative" class="panel-collapse collapse">
<div class="panel-body">
<p>Great job! Using relative paths to the files within your workflowr project makes it easier to run your code on other machines.</p>
</div>
</div>
</div>
<div class="panel panel-default">
<div class="panel-heading">
<p class="panel-title">
<a data-toggle="collapse" data-parent="#workflowr-checks" href="#strongRepositoryversionstrongahrefhttpsgithubcomcovid19forecasthubeuropeeurohubensembletree725dd314d9bfceab05ea8e2797376627875dad0etargetblank725dd31a"> <span class="glyphicon glyphicon-ok text-success" aria-hidden="true"></span> <strong>Repository version:</strong> <a href="https://github.com/covid19-forecast-hub-europe/euro-hub-ensemble/tree/725dd314d9bfceab05ea8e2797376627875dad0e" target="_blank">725dd31</a> </a>
</p>
</div>
<div id="strongRepositoryversionstrongahrefhttpsgithubcomcovid19forecasthubeuropeeurohubensembletree725dd314d9bfceab05ea8e2797376627875dad0etargetblank725dd31a" class="panel-collapse collapse">
<div class="panel-body">
<p>
Great! You are using Git for version control. Tracking code development and connecting the code version to the results is critical for reproducibility.
</p>
<p>
The results in this page were generated with repository version <a href="https://github.com/covid19-forecast-hub-europe/euro-hub-ensemble/tree/725dd314d9bfceab05ea8e2797376627875dad0e" target="_blank">725dd31</a>. See the <em>Past versions</em> tab to see a history of the changes made to the R Markdown and HTML files.
</p>
<p>
Note that you need to be careful to ensure that all relevant files for the analysis have been committed to Git prior to generating the results (you can use <code>wflow_publish</code> or <code>wflow_git_commit</code>). workflowr only checks the R Markdown file, but you know if there are other scripts or data files that it depends on. Below is the status of the Git repository when the results were generated:
</p>
<pre><code>
Ignored files:
    Ignored:    .Rhistory
    Ignored:    .Rproj.user/

Untracked files:
    Untracked:  analysis/.trackdown/

</code></pre>
<p>
Note that any generated files, e.g. HTML, png, CSS, etc., are not included in this status report because it is ok for generated content to have uncommitted changes.
</p>
</div>
</div>
</div>
</div>
<hr>
</div>
<div id="versions" class="tab-pane fade">

<p>
These are the previous versions of the repository in which changes were made to the R Markdown (<code>analysis/euro-hub-ensemble-draft.Rmd</code>) and HTML (<code>docs/euro-hub-ensemble-draft.html</code>) files. If you’ve configured a remote Git repository (see <code>?wflow_git_remote</code>), click on the hyperlinks in the table below to view the files as they were in that past version.
</p>
<div class="table-responsive">
<table class="table table-condensed table-hover">
<thead>
<tr>
<th>
File
</th>
<th>
Version
</th>
<th>
Author
</th>
<th>
Date
</th>
<th>
Message
</th>
</tr>
</thead>
<tbody>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/covid19-forecast-hub-europe/euro-hub-ensemble/blob/725dd314d9bfceab05ea8e2797376627875dad0e/analysis/euro-hub-ensemble-draft.Rmd" target="_blank">725dd31</a>
</td>
<td>
kathsherratt
</td>
<td>
2022-01-10
</td>
<td>
workflowr::wflow_publish(all = TRUE, update = TRUE)
</td>
</tr>
<tr>
<td>
html
</td>
<td>
<a href="https://rawcdn.githack.com/covid19-forecast-hub-europe/euro-hub-ensemble/a1b349049c974b698e1d542ca9e151a010fba4a8/docs/euro-hub-ensemble-draft.html" target="_blank">a1b3490</a>
</td>
<td>
kathsherratt
</td>
<td>
2022-01-10
</td>
<td>
Build site.
</td>
</tr>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/covid19-forecast-hub-europe/euro-hub-ensemble/blob/95f9770e2cd39ddb48180cdd3af7b3804a323859/analysis/euro-hub-ensemble-draft.Rmd" target="_blank">95f9770</a>
</td>
<td>
kathsherratt
</td>
<td>
2022-01-10
</td>
<td>
workflowr::wflow_publish(all = TRUE, update = TRUE)
</td>
</tr>
<tr>
<td>
html
</td>
<td>
<a href="https://rawcdn.githack.com/covid19-forecast-hub-europe/euro-hub-ensemble/95f9770e2cd39ddb48180cdd3af7b3804a323859/docs/euro-hub-ensemble-draft.html" target="_blank">95f9770</a>
</td>
<td>
kathsherratt
</td>
<td>
2022-01-10
</td>
<td>
workflowr::wflow_publish(all = TRUE, update = TRUE)
</td>
</tr>
<tr>
<td>
html
</td>
<td>
<a href="https://rawcdn.githack.com/covid19-forecast-hub-europe/euro-hub-ensemble/07f9c9124d1ec1aeff99cc15f1147426e95dd5d5/docs/euro-hub-ensemble-draft.html" target="_blank">07f9c91</a>
</td>
<td>
kathsherratt
</td>
<td>
2022-01-10
</td>
<td>
Build site.
</td>
</tr>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/covid19-forecast-hub-europe/euro-hub-ensemble/blob/2433343698800e3ca6af1151abb8383831e162c7/analysis/euro-hub-ensemble-draft.Rmd" target="_blank">2433343</a>
</td>
<td>
kathsherratt
</td>
<td>
2022-01-10
</td>
<td>
workflowr::wflow_publish(all = TRUE, update = TRUE)
</td>
</tr>
<tr>
<td>
html
</td>
<td>
<a href="https://rawcdn.githack.com/covid19-forecast-hub-europe/euro-hub-ensemble/2433343698800e3ca6af1151abb8383831e162c7/docs/euro-hub-ensemble-draft.html" target="_blank">2433343</a>
</td>
<td>
kathsherratt
</td>
<td>
2022-01-10
</td>
<td>
workflowr::wflow_publish(all = TRUE, update = TRUE)
</td>
</tr>
<tr>
<td>
html
</td>
<td>
<a href="https://rawcdn.githack.com/covid19-forecast-hub-europe/euro-hub-ensemble/1548c7247a39e7b6b7d67f4025aa3cc83e6f83ee/docs/euro-hub-ensemble-draft.html" target="_blank">1548c72</a>
</td>
<td>
kathsherratt
</td>
<td>
2022-01-10
</td>
<td>
Build site.
</td>
</tr>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/covid19-forecast-hub-europe/euro-hub-ensemble/blob/feb46799638b3ca9a5fec8e34b522d01b41e1401/analysis/euro-hub-ensemble-draft.Rmd" target="_blank">feb4679</a>
</td>
<td>
kathsherratt
</td>
<td>
2022-01-10
</td>
<td>
workflowr::wflow_publish(all = TRUE, update = TRUE)
</td>
</tr>
<tr>
<td>
html
</td>
<td>
<a href="https://rawcdn.githack.com/covid19-forecast-hub-europe/euro-hub-ensemble/feb46799638b3ca9a5fec8e34b522d01b41e1401/docs/euro-hub-ensemble-draft.html" target="_blank">feb4679</a>
</td>
<td>
kathsherratt
</td>
<td>
2022-01-10
</td>
<td>
workflowr::wflow_publish(all = TRUE, update = TRUE)
</td>
</tr>
<tr>
<td>
html
</td>
<td>
<a href="https://rawcdn.githack.com/covid19-forecast-hub-europe/euro-hub-ensemble/2e33ed6d3694c36eec60026cc2ff0774c88afbc7/docs/euro-hub-ensemble-draft.html" target="_blank">2e33ed6</a>
</td>
<td>
kathsherratt
</td>
<td>
2022-01-10
</td>
<td>
Build site.
</td>
</tr>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/covid19-forecast-hub-europe/euro-hub-ensemble/blob/4194f57359681e7690c322e3573921ada8ed1fe3/analysis/euro-hub-ensemble-draft.Rmd" target="_blank">4194f57</a>
</td>
<td>
kathsherratt
</td>
<td>
2022-01-10
</td>
<td>
workflowr::wflow_publish(all = TRUE, update = TRUE)
</td>
</tr>
<tr>
<td>
html
</td>
<td>
<a href="https://rawcdn.githack.com/covid19-forecast-hub-europe/euro-hub-ensemble/4194f57359681e7690c322e3573921ada8ed1fe3/docs/euro-hub-ensemble-draft.html" target="_blank">4194f57</a>
</td>
<td>
kathsherratt
</td>
<td>
2022-01-10
</td>
<td>
workflowr::wflow_publish(all = TRUE, update = TRUE)
</td>
</tr>
<tr>
<td>
html
</td>
<td>
<a href="https://rawcdn.githack.com/covid19-forecast-hub-europe/euro-hub-ensemble/f57e78f8efd64fe567c44d245a4e3b3b51e8ad36/docs/euro-hub-ensemble-draft.html" target="_blank">f57e78f</a>
</td>
<td>
kathsherratt
</td>
<td>
2022-01-10
</td>
<td>
Build site.
</td>
</tr>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/covid19-forecast-hub-europe/euro-hub-ensemble/blob/0316e856beef795c826c492509ddef5833568473/analysis/euro-hub-ensemble-draft.Rmd" target="_blank">0316e85</a>
</td>
<td>
kathsherratt
</td>
<td>
2022-01-10
</td>
<td>
workflowr::wflow_publish(all = TRUE, update = TRUE)
</td>
</tr>
<tr>
<td>
html
</td>
<td>
<a href="https://rawcdn.githack.com/covid19-forecast-hub-europe/euro-hub-ensemble/0316e856beef795c826c492509ddef5833568473/docs/euro-hub-ensemble-draft.html" target="_blank">0316e85</a>
</td>
<td>
kathsherratt
</td>
<td>
2022-01-10
</td>
<td>
workflowr::wflow_publish(all = TRUE, update = TRUE)
</td>
</tr>
<tr>
<td>
html
</td>
<td>
<a href="https://rawcdn.githack.com/covid19-forecast-hub-europe/euro-hub-ensemble/4bd6ab89de99e4d446b846eb5969b6134a68628b/docs/euro-hub-ensemble-draft.html" target="_blank">4bd6ab8</a>
</td>
<td>
kathsherratt
</td>
<td>
2022-01-10
</td>
<td>
Build site.
</td>
</tr>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/covid19-forecast-hub-europe/euro-hub-ensemble/blob/b05155e6d4160d8302a396c42356b8a5da4029b7/analysis/euro-hub-ensemble-draft.Rmd" target="_blank">b05155e</a>
</td>
<td>
kathsherratt
</td>
<td>
2022-01-10
</td>
<td>
workflowr::wflow_publish(all = TRUE, update = TRUE)
</td>
</tr>
<tr>
<td>
html
</td>
<td>
<a href="https://rawcdn.githack.com/covid19-forecast-hub-europe/euro-hub-ensemble/b05155e6d4160d8302a396c42356b8a5da4029b7/docs/euro-hub-ensemble-draft.html" target="_blank">b05155e</a>
</td>
<td>
kathsherratt
</td>
<td>
2022-01-10
</td>
<td>
workflowr::wflow_publish(all = TRUE, update = TRUE)
</td>
</tr>
<tr>
<td>
html
</td>
<td>
<a href="https://rawcdn.githack.com/covid19-forecast-hub-europe/euro-hub-ensemble/a88dfac57096a5e2c0ee2aa6a416b42a6398865e/docs/euro-hub-ensemble-draft.html" target="_blank">a88dfac</a>
</td>
<td>
kathsherratt
</td>
<td>
2022-01-07
</td>
<td>
Build site.
</td>
</tr>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/covid19-forecast-hub-europe/euro-hub-ensemble/blob/98ecf0bc7d80259cdb4794b64049e631600e35b3/analysis/euro-hub-ensemble-draft.Rmd" target="_blank">98ecf0b</a>
</td>
<td>
kathsherratt
</td>
<td>
2022-01-07
</td>
<td>
workflowr::wflow_publish(all = TRUE, update = TRUE)
</td>
</tr>
<tr>
<td>
html
</td>
<td>
<a href="https://rawcdn.githack.com/covid19-forecast-hub-europe/euro-hub-ensemble/98ecf0bc7d80259cdb4794b64049e631600e35b3/docs/euro-hub-ensemble-draft.html" target="_blank">98ecf0b</a>
</td>
<td>
kathsherratt
</td>
<td>
2022-01-07
</td>
<td>
workflowr::wflow_publish(all = TRUE, update = TRUE)
</td>
</tr>
<tr>
<td>
html
</td>
<td>
<a href="https://rawcdn.githack.com/covid19-forecast-hub-europe/euro-hub-ensemble/48c660fcdc4b2841baa1f810ddc74ae8ecc372bd/docs/euro-hub-ensemble-draft.html" target="_blank">48c660f</a>
</td>
<td>
kathsherratt
</td>
<td>
2022-01-05
</td>
<td>
Build site.
</td>
</tr>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/covid19-forecast-hub-europe/euro-hub-ensemble/blob/0358deeb73131dd03f23e5d0c7bcdb993ed1f145/analysis/euro-hub-ensemble-draft.Rmd" target="_blank">0358dee</a>
</td>
<td>
kathsherratt
</td>
<td>
2022-01-05
</td>
<td>
workflowr::wflow_publish(all = TRUE, update = TRUE)
</td>
</tr>
<tr>
<td>
html
</td>
<td>
<a href="https://rawcdn.githack.com/covid19-forecast-hub-europe/euro-hub-ensemble/135822c060d5b8156a0bd0cc82ff34ddf6b6ab67/docs/euro-hub-ensemble-draft.html" target="_blank">135822c</a>
</td>
<td>
kathsherratt
</td>
<td>
2022-01-05
</td>
<td>
Build site.
</td>
</tr>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/covid19-forecast-hub-europe/euro-hub-ensemble/blob/ca19fa003f7baca5ed2c7a4a8b2b6aa0b0db7762/analysis/euro-hub-ensemble-draft.Rmd" target="_blank">ca19fa0</a>
</td>
<td>
kathsherratt
</td>
<td>
2022-01-05
</td>
<td>
workflowr::wflow_publish(all = TRUE, update = TRUE)
</td>
</tr>
<tr>
<td>
html
</td>
<td>
<a href="https://rawcdn.githack.com/covid19-forecast-hub-europe/euro-hub-ensemble/c2b25dc862934dcc642a8be54681cd5eee2354ae/docs/euro-hub-ensemble-draft.html" target="_blank">c2b25dc</a>
</td>
<td>
kathsherratt
</td>
<td>
2021-12-06
</td>
<td>
Build site.
</td>
</tr>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/covid19-forecast-hub-europe/euro-hub-ensemble/blob/1be56c8a9daab09e1289c37d6a4d3baac3ef411a/analysis/euro-hub-ensemble-draft.Rmd" target="_blank">1be56c8</a>
</td>
<td>
kathsherratt
</td>
<td>
2021-12-06
</td>
<td>
workflowr::wflow_publish(all = TRUE, update = TRUE)
</td>
</tr>
<tr>
<td>
html
</td>
<td>
<a href="https://rawcdn.githack.com/covid19-forecast-hub-europe/euro-hub-ensemble/a8920fc3bbfd18f33ac7d2362c895e493f117c3a/docs/euro-hub-ensemble-draft.html" target="_blank">a8920fc</a>
</td>
<td>
kathsherratt
</td>
<td>
2021-12-06
</td>
<td>
Build site.
</td>
</tr>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/covid19-forecast-hub-europe/euro-hub-ensemble/blob/29b235cec2eb85225bb0619882b39032f09a8dee/analysis/euro-hub-ensemble-draft.Rmd" target="_blank">29b235c</a>
</td>
<td>
kathsherratt
</td>
<td>
2021-12-06
</td>
<td>
change title
</td>
</tr>
<tr>
<td>
html
</td>
<td>
<a href="https://rawcdn.githack.com/covid19-forecast-hub-europe/euro-hub-ensemble/29b235cec2eb85225bb0619882b39032f09a8dee/docs/euro-hub-ensemble-draft.html" target="_blank">29b235c</a>
</td>
<td>
kathsherratt
</td>
<td>
2021-12-06
</td>
<td>
change title
</td>
</tr>
</tbody>
</table>
</div>
<hr>
</div>
</div>
</div>
<p><em>Order tbc;</em> Katharine Sherratt, Hugo Gruson, <em>Any co-authors</em>, <em>Team authors</em>, <em>Advisory team authors</em>, <em>ECDC authors</em>, Johannes Bracher, Sebastian Funk</p>
<div id="abstract" class="section level1">
<h1>Abstract</h1>
<p><em>Background</em> Short-term forecasts of infectious disease burden can contribute to situational awareness and aid capacity planning. Based on best practice in other fields and recent insights in infectious disease epidemiology, one can maximise the predictive performance of such forecasts if multiple models are combined into an ensemble. Here we report on the performance of ensembles created from over 40 models in predicting COVID-19 cases and deaths across Europe.</p>
<p><em>Methods</em> We adopted existing infrastructure to develop a public European Covid-19 Forecast Hub. We invited groups globally to contribute weekly forecasts for Covid-19 cases and deaths over the next one to four weeks. Forecasts included quantiles across the predictive distribution. Each week we created an ensemble forecast, where each predictive quantile was calculated as the equally-weighted average of all individual models’ predictive quantiles. We retrospectively explored alternative methods for ensemble forecasts, including weighted averages based on models’ past predictive skill. The performance of the ensembles was compared to individual models and a baseline model of no change using pairwise comparison with the Weighted Interval Score (WIS).</p>
<p><em>Results</em> We collected and combined 36 weeks of forecasts for 32 countries from 43 forecast models. We found the weekly ensemble had among the most reliable performances across countries over time, outperforming the baseline for 67% and 91% of targets for cases and deaths, respectively. Ensemble performance declined with increasing forecast time horizon when forecasting cases but remained stable for 4 weeks for incident death forecasts. Among several choices of ensemble methods, we found that regardless of methods for weighting component forecasts, the calculation of the average was the most influential choice for performance, with almost any forecast created using a median average performing better than using a mean.</p>
<p><em>Conclusions</em> Our results support the use of an ensemble as a reliable way to make real-time forecasts across many populations and epidemiological targets during infectious disease epidemics. We recommend the use of median ensemble methods, and that policy relevant work that uses ensembles should place more confidence in forecasts of incident death than case counts, particularly at longer (more than 2 week) periods into the future.</p>
</div>
<div id="background" class="section level1">
<h1>Background</h1>
<p>Epidemiological forecasts make quantitative statements about a disease outcome in the near future. At the most general level, forecasting targets can include measures of prevalent or incident disease and its severity, for some population over a specified time horizon. Researchers, policy makers, and the general public have used such forecasts to understand and respond to the global outbreaks of Covid-19 since early 2020 <span class="citation">[@basshuysenThreeWaysWhich2021]</span>. However forecasters use a variety of methods and models for creating and publishing forecasts, varying in both defining the forecast outcome and in reporting the distribution of probability around outcomes <span class="citation">[@zelnerAccountingUncertaintyPandemic2021; @jamesUseMisuseMathematical2021]</span>. Such variation between forecasts makes it difficult to interpret the likelihood of any one outcome, or to compare the predictive performance between forecast models. These barriers to comparing and evaluating mean there is little objective support for using any one particular forecast for representing or acting on likely outcomes.</p>
<p>A “forecast hub” is a centralised effort to improve the transparency and usefulness of forecasts, by standardising and collating the work of many independent teams producing forecasts <span class="citation">[@reichCollaborativeMultiyearMultimodel2019]</span>. A hub sets a commonly agreed structure for forecast targets, such as type of disease event, spatio-temporal units, or the set of quantiles of the probability distribution to include from probabilistic forecasts. Forecasters can adopt this format and contribute forecasts for centralised storage in the public domain. This shared infrastructure allows forecasts produced from diverse teams and methods to be visualised and quantitatively compared on a near-exact like-for-like basis, which can strengthen public and policy use of disease forecasts <span class="citation">[@cdcCoronavirusDisease20192020]</span>. The underlying approach to creating a forecast hub was pioneered for forecasting influenza in the USA and adapted for forecasts of short-term Covid-19 cases and deaths in the US <span class="citation">[@rayEnsembleForecastsCoronavirus2020e]</span>, with similar efforts elsewhere <span class="citation">[@bracherPreregisteredShorttermForecasting2021; @funkShorttermForecastsInform2020; @bicherSupportingCOVID19PolicyMaking2021]</span>.</p>
<p>Standardising forecasts may also allow us to maximise their predictive performance by combining multiple forecasts into a single ensemble forecast. Evidence from previous efforts in multi-model infectious disease forecasting suggests that forecasts from an ensemble of many forecast models can be consistently high performing compared to any one of the component models <span class="citation">[@reichAccuracyRealtimeMultimodel2019a; @johanssonOpenChallengeAdvance2019; @viboudRAPIDDEbolaForecasting2018]</span>. Somewhat comparably, weather forecasting has a long standing use of building ensembles of many models using diverse methods with standardised data and formatting <span class="citation">[@buizzaIntroductionSpecialIssue2019; @moranEpidemicForecastingMessier2016a]</span>.</p>
<p>The European Covid-19 Forecast Hub <span class="citation">[@europeancovid-19forecasthubEuropeanCOVID19Forecast2021]</span> is a project to collate short term forecasts of Covid-19 across 32 countries in the European region. The Hub is supported by the European Centre for Disease Control (ECDC), with the primary aim to provide reliable information about the near-term epidemiology of the COVID-19 pandemic to the research and policy communities and the general public. Second, the hub aims to create infrastructure for storing and analysing epidemiological forecasts made in real time by diverse research teams and methods across Europe. Third, the hub aims to maintain a community of infectious disease modellers underpinned by open science principles. We started formally collating and combining contributions to the European Forecast Hub in March 2021. Here, we investigate the predictive performance of an ensemble of all forecasts contributed to the hub in real time each week, as well as the performance of variations of ensemble methods created retrospectively.</p>
</div>
<div id="methods" class="section level1">
<h1>Methods</h1>
<p>We developed infrastructure to host and analyse forecasts, following a similar structure and data format, and adapted processes and software provided by the US <span class="citation">[@cramerReichlabCovid19forecasthubRelease2021; @wangReichlabCovidHubUtilsRepository2021]</span> and the German and Polish COVID-19 <span class="citation">[@bracherGermanPolishCOVID192020]</span> forecast hubs.</p>
<div id="forecast-targets-and-standardisation" class="section level3">
<h3>Forecast targets and standardisation</h3>
<p>We sought forecasts for reported weekly incident counts of cases and deaths from COVID-19 for each of 32 countries in Europe (including all countries of the European Union and European Free Trade Area, and separately the United Kingdom). Incidence was aggregated over the Morbidity and Mortality Weekly Report (MMWR) epidemiological week definition of Sunday through Saturday. When predicting any single forecast target, teams could express uncertainty by submitting predictions across a range of a pre-specified set of 23 quantiles in the probability distribution. Teams could also submit a single point forecast without uncertainty. At the first submission we asked teams to add a single set of metadata briefly describing the forecasting team and methods. Model types included mechanistic models, agent-based and statistical models, ensembles of multiple models and an expertise-based model. We maintain a full project specification with a detailed submissions protocol <span class="citation">[@europeancovid-19forecasthubCovid19forecasthubeuropeWiki]</span>.</p>
<p>With the complete dataset for the latest forecasting week available each Sunday, forecasts were typically submitted to the hub on Monday. We used an automated validation programme to check that each new forecast conformed to standardised formatting. This included checking that predictions increased monotonically with each increasing quantile, that predictions were integer counts, as well as that forecasts conformed to consistent date and location definitions.</p>
<p>Each week we built an ensemble of all forecasts which was updated each week after all forecasts had been validated. From the first week of forecasting from 8 March 2021, the ensemble method for summarising across forecasts was the mean average of all models at each predictive quantile for a given location, target, and horizon. From 26 July 2021 onwards the ensemble instead used a median average of all predictive quantiles, in order to mitigate the wide uncertainty produced by some highly anomalous forecasts. We created an open and publicly accessible interface to the forecasts and ensemble, including an online visualization tool allowing viewers to see past data and interact with one or multiple forecasts for each country and target for up to four weeks’ horizon <span class="citation">[@europeancovid-19forecasthubEuropeanCovid19Forecast]</span>. All forecast and meta data are freely available and held on Zoltar, a platform for hosting epidemiological forecasts (<span class="citation">@epiforecastsProjectECDCEuropean2021</span>; reichZoltarForecastArchive2021).</p>
</div>
<div id="forecast-evaluation" class="section level3">
<h3>Forecast evaluation</h3>
<p>We evaluated all previous forecasts against actual observed values for each model, stratified by the forecast horizon, location, and target. We calculated scores using the <em>scoringutils</em> R package <span class="citation">[@nikosibosseScoringutilsUtilitiesScoring2020]</span> with observed data reported by Johns Hopkins University (JHU, <span class="citation">[@dongInteractiveWebbasedDashboard2020a]</span>). JHU data included a mix of national and aggregated subnational data for the 32 countries in the Hub. We removed any forecast surrounding (in the week of or after) a strongly anomalous data point.</p>
<p>We assessed calibration via coverage of the predictive intervals and overall predictive performance via the weighted interval score (WIS). Coverage at a given interval level <span class="math inline">\(k\)</span> was calculated as the proportion <span class="math inline">\(p\)</span> of observations that fell within the corresponding central predictive intervals across locations and forecast dates. A perfectly calibrated model would have <span class="math inline">\(p=k\)</span> at all 11 levels (corresponding to 22 quantiles excluding the median). An underconfident model at level <span class="math inline">\(k\)</span> would have <span class="math inline">\(p&gt;k\)</span>, i.e. more observations falling within a given interval than expected, whereas an overconfident model at level <span class="math inline">\(k\)</span> would have <span class="math inline">\(p&lt;k\)</span>, i.e. fewer observations falling within a given interval than expected. We here focus on coverage at the 50% and 95% level.</p>
<p>We assessed weekly forecasts using the WIS across all quantiles that were being gathered<span class="citation">[@bracherEvaluatingEpidemicForecasts2021]</span>. This WIS is a strictly proper scoring rule, that is, it is optimised for predictions that come from the data-generating model and, as a consequence, encourages forecasters to report predictions representing their true belief about the future<span class="citation">[@gneitingStrictlyProperScoring2007]</span>. The WIS represents a parsimonious approach to scoring forecasts when only quantiles are available:</p>
<p><span class="math display">\[\mathrm{WIS}_{\alpha_{0:K}}(y, F) = \frac{1}{K + 0.5} \left( \frac{1}{2} \left| y - m \right| + \sum_{k=1}^{K} \left(\frac{\alpha_k}{2} \left(u_k - l_k \right) + \left( l_k - y \right) \mathbb{I}_{y &lt; l_k} + \left( y - u_k \right) \mathbb{I}_{y &gt; l_k} \right) \right)\]</span></p>
<p>Where <span class="math inline">\(y\)</span> is an observed outcome, <span class="math inline">\(F\)</span> the forecast, <span class="math inline">\(m\)</span> the median of the predictive distribution, <span class="math inline">\(u_k\)</span> and <span class="math inline">\(l_k\)</span> are the predictive upper and lower quantiles corresponding to the central predictive interval level <span class="math inline">\(k\)</span>, respectively, <span class="math inline">\(K=11\)</span> is the number of intervals considered and <span class="math inline">\(1 - \alpha_k\)</span> the width of central predictive interval <span class="math inline">\(k\)</span>.</p>
<p>Not all models were used to generate forecasts for all locations and all forecast dates. In order to be able to compare predictive performance in the face of various levels of missingness, we further calculated a relative WIS as a relative measure of forecast performance which takes into account that different teams may not cover the exact same set of forecast targets (i.e., weeks and locations). Loosely speaking, a relative WIS of X means that averaged over the targets a given team addressed, its WIS was X times higher/lower than the the performance of the baseline model assuming case/death numbers to stay the same in the future, described previously<span class="citation">[@cramerEvaluationIndividualEnsemble2021c]</span>. Smaller values are thus better and a value below one means that the model has above average performance. The relative WIS is computed using a ?pairwise comparison tournament? where for each pair of models a mean score ratio is computed based on the set of shared targets. The relative WIS of a model with respect to another model is then the ratio of their respective geometric mean of the mean score ratios, where here we report the relative WIS of each model with respect to the baseline model.</p>
<div id="ensemble-methods" class="section level4">
<h4>Ensemble methods</h4>
<p>We retrospectively explored alternative methods for ensembling forecasts for each target each week. A natural way to combine probability distributions available in a quantile format, such as the ones collated in the European Covid-19 Forecast Hub is<span class="citation">[@genestVincentizationRevisited1992]</span> <span class="math display">\[F^{-1}(\alpha) = \sum_{i=1}^{n}w_i F_i^{-1}(\alpha)\]</span> Where <span class="math inline">\(F_{1 \ldots n}\)</span> are the cumulative distribution functions of the individual probability distributions (in our case, the predictive distributions of the forecasts contributed to the hub), <span class="math inline">\(w_i\)</span> are a set of weights; and <span class="math inline">\(\alpha\)</span> are the quantile levels such that <span class="math display">\[F^{-1}(\alpha) = \mathrm{inf} \{t : F_i(t) \geq \alpha \}\]</span>. Different ensemble choices then largely come down to the choice of weights <span class="math inline">\(w_i\)</span>.</p>
<p>The simplest choice of weights is to set them all equal so that they sum up to 1, <span class="math inline">\(w_i=1/n\)</span>,, resulting in an unweighted mean ensemble. This can be subject to outlier forecasts that could skew the mean. A choice that avoids this potential issue is to combine the forecasts at each quantile level in an unweighted median ensemble, where the average is replaced by a median. An unweighted median ensemble has previously been found to yield very competitive performance while maintaining robustness to outlying forecast<span class="citation">[@rayChallengesTrainingEnsembles2021]</span>. By choosing the weights <span class="math inline">\(w_i\)</span> to reflect past performance one can move from an untrained to a trained ensemble. Numerous options exist for choosing the weights with the aim to maximise predictive performance. A straightforward choice is so-called inverse score weighting, which was recently found in the US to outperform unweighted scores during some time periods<span class="citation">[@taylorCombiningProbabilisticForecasts2021]</span> but not confirmed in a similar study in Germany and Poland <span class="citation">[@bracherPreregisteredShorttermForecasting2021]</span>. In this case, the weights are calculated as <span class="math display">\[w_i = \frac{1}{S_i}\]</span> where <span class="math inline">\(S_i\)</span> reflects the forecast skill of forecaster <span class="math inline">\(i\)</span>.</p>
<p>Here we considered unweighted and inverse relative WIS weighted mean and median ensembles. We additionally considered ensembles where the training period was restricted to the last 10 weeks (for the weighted ensembles), or where only models with relative WIS &lt; 1 (i.e., outperforming the baseline) were admitted included.</p>
</div>
</div>
</div>
<div id="results" class="section level1">
<h1>Results</h1>
<p>We scored all forecasts submitted weekly in real time over the 36 week period from 08 March to 15 November 2021. Each week, forecasts were collated for incident cases and deaths, for 32 locations over the following 4 weeks, creating 256 possible forecast targets. We received 43 unique forecasting models from 36 separate forecasting teams. We added an ensemble model using all available forecasts for each possible target every week.</p>
<p>We used this dataset to create 3998 forecasting scores, each summarising a unique combination of model, variable, country, and week ahead horizon. Not all teams forecast for all targets, nor across all quantiles of the predictive distribution for each target. 37 models provided sufficient quantiles that we could evaluate them using the relative weighted interval score (WIS).</p>
<div class="figure" style="text-align: center">
<img src="figure/euro-hub-ensemble-draft.Rmd/figure-1-model-by-horizon-1.png" alt="Figure 1: Performance of short-term forecasts, by relative interval score (relative to a baseline forecast, top) and coverage of the central 50% interval (the proportion of observed values that fell within the predicted 50% range, bottom). The scores of each model (grey) and ensemble (red) are averaged across all forecast targets and shown by one- to four-week ahead horizon." width="672" />
<p class="caption">
Figure 1: Performance of short-term forecasts, by relative interval score (relative to a baseline forecast, top) and coverage of the central 50% interval (the proportion of observed values that fell within the predicted 50% range, bottom). The scores of each model (grey) and ensemble (red) are averaged across all forecast targets and shown by one- to four-week ahead horizon.
</p>
</div>
<p>The ensemble model performed well compared to both its component models and the baseline. In ranking all models’ scores compared to the baseline, the ensemble performed better on relative WIS than 66% model scores when forecasting cases (n=1832), and 67% of scores for forecasts of incident deaths (n=1910). Compared to the baseline model alone, the ensemble outperformed it at the one-week ahead horizon for both cases and deaths (figure 1). For horizons longer than one week, performance depended on the epidemiological target. The ensemble stopped outperforming the baseline at three to four weeks for cases. In contrast, the ensemble outperformed the baseline for deaths at all horizons considered (up to four weeks WIS), with no discernible deterioration in performance.</p>
<p>We observed similar trends in performance when considering how well the ensemble was calibrated with respect to the observed data. At one week ahead the case ensemble was well calibrated (ca. 50% nominal coverage at the 50% level), but this did not hold with increasing forecast horizon. The death ensemble was well calibrated at the 95% level for all horizons and under confident for the 50% level, with only slow deterioration with increasing forecast horizon.</p>
<div class="figure" style="text-align: center">
<img src="figure/euro-hub-ensemble-draft.Rmd/figure-2-model-by-location-1.png" alt="Figure 2: Performance of short-term forecasts across models and median ensemble (asterisk), by country, forecasting cases (top) and deaths (bottom) for two-week ahead forecasts, according to the relative weighted interval score. Boxplots show interquartile ranges, with outliers as faded points, and the ensemble model performance is marked by an asterisk." width="672" />
<p class="caption">
Figure 2: Performance of short-term forecasts across models and median ensemble (asterisk), by country, forecasting cases (top) and deaths (bottom) for two-week ahead forecasts, according to the relative weighted interval score. Boxplots show interquartile ranges, with outliers as faded points, and the ensemble model performance is marked by an asterisk.
</p>
</div>
<p>The ensemble also performed consistently well when forecasting across countries relative to individual models and the baseline (figure 2, figure SI1). Compared to models that forecast across all 32 countries at the two-week horizon, the ensemble was more consistent in outperforming the baseline across countries compared to any single model forecasting deaths, and all but one model for case forecasts. Considering forecast targets across all 32 countries and over all four horizons (128 targets), the ensemble forecast outperformed the baseline for 67% and 91% of all 128 targets when forecasting cases and deaths, respectively[j]. Comparably, the best individual models forecasting for the same number of targets as the ensemble model outperformed the baseline for 80% (“LANL-GrowthRate” model) for cases and 81% (“81” model) for death forecasts.</p>
<div class="figure" style="text-align: center">
<img src="figure/euro-hub-ensemble-draft.Rmd/figure-3-alternative-ensembles-1.png" alt="Figure 3: Performance of alternative ensemble methods at 2 week horizon, showing mean difference (triangle) in relative weighted interval score, with 48% and 96% probability (thick and thin line respectively). The difference in WIS is a comparison of scores from forecasts made from all possible combinations of methods, with a single element of ensemble method input changed. Reference categories are: weighted v. unweighted (n=250); median v. mean (n=376); cutoff by WIS v. all models included (n=374); relative WIS measures over 10 weeks of forecast history vs. all forecasts (n=248)" width="672" height="50%" />
<p class="caption">
Figure 3: Performance of alternative ensemble methods at 2 week horizon, showing mean difference (triangle) in relative weighted interval score, with 48% and 96% probability (thick and thin line respectively). The difference in WIS is a comparison of scores from forecasts made from all possible combinations of methods, with a single element of ensemble method input changed. Reference categories are: weighted v. unweighted (n=250); median v. mean (n=376); cutoff by WIS v. all models included (n=374); relative WIS measures over 10 weeks of forecast history vs. all forecasts (n=248)
</p>
</div>
<p>At the two-week ahead horizon, variations in ensemble methods made little difference to forecast scores (figure 3, figure SI2). Ensembles that weighted forecasts showed no difference in performance to simple unweighted ensemble methods. Similarly, in choosing a method with which to weight forecasts, the choice of whether to use scores across all past forecasts, or scores evaluating only the most recent 10 weeks’ forecast scores, made very little difference to the performance of the resulting ensemble (0 mean change in forecast score). The choice to exclude any forecast that scored worse than the baseline forecast (“cut off”) affected the performance of the ensemble in both directions, overall slightly worsening performance (0.07 relative WIS). Using the median average was the only variation of ensemble method that typically improved performance, compared to using the mean average across any combination of ensemble method.</p>
</div>
<div id="discussion" class="section level1">
<h1>Discussion</h1>
<p>We collated forecasts from multiple teams making forecasts of COVID-19 cases and deaths across countries over March to November in Europe, using an open and principled approach to standardising both forecast targets and the uncertainty around predictions. Combining these forecasts into an ensemble we found that the ensemble forecasts outperformed a baseline model at short forecast horizons and produced among the most consistent predictive performance across countries over time.</p>
<p>Our results support previous findings that ensembles are or are near the best performing models by error and are the most reliably consistent models in terms of appropriate coverage of uncertainty <span class="citation">[@funkShorttermForecastsInform2020; @cramerEvaluationIndividualEnsemble2021c]</span>. While the ensemble was consistently high performing, it was not strictly dominant across all forecast targets, with others also seeing this in comparable studies of Covid-19 forecasts <span class="citation">[@bracherPreregisteredShorttermForecasting2021; @brooksComparingEnsembleApproaches2020]</span>. This finding suggests the usefulness of an ensemble as a robust summary when forecasting across many spatio-temporal targets, without replacing the importance of communicating the full range of model predictions.</p>
<p>We can identify the benefits of an ensemble approach in light of the epidemic dynamics of Covid-19 in Europe over March to November. The introduction of vaccination changed the associations between infections, cases, and deaths <span class="citation">[@europeancentrefordiseasepreventionandcontrolInterimGuidanceBenefits2021]</span>. At the same time, the emergence of the delta variant altered transmission dynamics as it became the dominant viral strain across Europe <span class="citation">[@europeancentrefordiseasepreventionandcontrolThreatAssessmentBrief2021]</span>. However, neither of these factors were uniform across countries covered by the Forecast Hub <span class="citation">[@europeancentrefordiseasepreventionandcontrolOverviewImplementationCOVID192021]</span>. As epidemic dynamics became increasingly heterogeneous, the forecasting performance of any single model over time and across multiple countries became at least partly dependent on the ability, speed, and precision with which it could adapt to new conditions for each forecast target. This variability in the relative performance of models over time makes using an ensemble, balancing across all models, particularly relevant in rapidly changing epidemic conditions.</p>
<p>Our results also suggest the limited value of reporting case forecasts further than two weeks into the future. Previous work has similarly found rapidly declining performance for case forecasts with increasing horizon <span class="citation">[@cramerEvaluationIndividualEnsemble2021c]</span>. Covid-19 has a typical serial interval of less than a week, meaning that case forecasts of over two weeks can only hold if rates of transmission and detection remain predictable over the entire period, a strong assumption in the light of the many instances of rapidly changing policies and individual behaviour observed during the pandemic.</p>
<p>In contrast, our ensemble, its component models, and previous work all highlight the more stable performance of death forecasts over time horizon. The ensemble in this study continued to outperform the baseline at four weeks ahead, and other work has found death forecasts perform well with up to six weeks lead time <span class="citation">[@friedmanPredictivePerformanceInternational2021]</span>. We could interpret this as due to the longer time lag between infection and death, which allows forecasters to incorporate the effect of changes in transmission. Additionally, the performance of trend-based forecasts may have benefited from the slower changes to trends in incident deaths caused by increasing vaccination rates, in turn supporting the performance of the ensemble.</p>
<p>Exploring variations in ensemble methods we found that the choice of simple mean or median average had the most consistent impact on performance, regardless of methods of weighting and inclusion by performance history. Other work has supported the importance of the median in providing a stable forecast that better accounts for outliers than the mean <span class="citation">[@brooksComparingEnsembleApproaches2020]</span>. However, our results did not show a strong performance benefit for any one methodological choice, joining the existing mixed evidence for any optimal ensemble method for combining short term probabilistic infectious disease forecasts. In similar analyses of US Covid-19 forecasts many methods of combination have performed competitively, including the simple mean and weighted approaches outperforming unweighted or median methods <span class="citation">[@taylorCombiningProbabilisticForecasts2021]</span>. This contrasts with later analyses finding weighted methods to give similar performance to a median average <span class="citation">[@brooksComparingEnsembleApproaches2020; @rayEnsembleForecastsCoronavirus2020e]</span>. We can partly explain this inconsistency if performance of each method depends on the outcome being predicted (cases, deaths), its count (incident, cumulative) and absolute level, and the varying quality and quantity of forecasting teams over time.</p>
<p>We also identified benefits of our approach beyond the results of this analysis. Open access to visualised forecasts and data is useful for both academics and the public in an emergency setting when forecasts can influence individual to international actions that change epidemic dynamics <span class="citation">[@basshuysenThreeWaysWhich2021]</span>. Existing participatory modelling efforts for Covid-19 have been useful for policy communication <span class="citation">[@cdcCoronavirusDisease20192020]</span>, while multi-country efforts have included only single models adapted to country-specific parameters <span class="citation">[@aguasModellingCOVID19Pandemic2020; @adibParticipatoryModellingApproach2021]</span>. By expanding participation to many modelling teams, our work can create robust ensemble forecasts across Europe while allowing comparison across forecasts built with different interpretations of current data, on a like for like scale in real time. At the same time, collating time-stamped predictions ensures that we can test true out-of-sample performance of models and avoid retrospective claims of performance. Testing the limits of forecasting ability with these comparisons forms an important part of communicating any model-based prediction to decision makers.</p>
<p>However, we experienced several limitations to our approach. First, our assessment of individual model performance may have been inaccurate due to limitations in the data source used. We saw some real time data revised retrospectively, introducing bias in either direction where the data used to create forecasts was not the same as that used to evaluate it. We mitigated this by excluding forecasts made at or for a time of missing, unreliable, or heavily revised data. We used a manual process for determining anomalous data, and if we did not detect where data revisions affected forecasts this could have created inaccurate forecast scores. However, we note that the national data used here are less likely to see revisions than subnational data <span class="citation">[@dongInteractiveWebbasedDashboard2020a]</span>.</p>
<p>The results presented also depend on our choice of performance metric. While other work supports the use of the weighted interval score <span class="citation">[@bracherEvaluatingEpidemicForecasts2021, @gneitingStrictlyProperScoring2007; @taylorCombiningProbabilisticForecasts2021]</span>, our use of a flat-line comparison meant that it was more difficult for forecasts to perform well in relative terms during periods where incidence was very stable <span class="citation">[@cramerEvaluationIndividualEnsemble2021c]</span>. This may have differentially biased forecast performance where, for equally good forecasts for different targets, models that predicted a change in trend were rewarded with better scores than those that equally accurately predicted a stable continuation. Further work could consider how well our results compare when using an alternative baseline suitable for epidemics, for example an exponential growth model.</p>
<p>The result that the ensemble was among the most reliable across countries and over time could also have been influenced by the sample of contributing forecasts. We accepted all modelling teams’ participation and teams used a wide variety of methods. Meanwhile, teams may have changed their forecast methods, and entered and exited the hub over time. The ensemble therefore included forecasts based on models with changing assumptions each week, and we did not test how far the stability or methods of component forecasts influenced the resulting ensemble. This could be significant, for example where in a time of low incidence, including only compartmental models in an ensemble improved predictive performance relative to including forecasts from a wider variety of methods <span class="citation">[@taylorCombiningProbabilisticForecasts2021]</span>. However, the same study found the most consistent ensemble over time was that which included all forecasts regardless of method, with performance increasing with the number of forecast models, so our results are unlikely to have changed by excluding any contributing forecasts.</p>
<p>We see additional scope to adapt the hub to the changing Covid-19 situation across Europe. We have recently extended the hub infrastructure to include short term forecasts for hospitalisations with COVID-19, although this faces additional challenges with limited data across the locations covered by the hub. It may also be valuable to separately investigate models for longer term scenarios in addition to the short term forecasts, particularly as the policy focus shifts from immediate response to anticipating changes brought by vaccinations or the geographic spread of new variants <span class="citation">[@europeancentrefordiseasepreventionandcontrolOverviewImplementationCOVID192021]</span>.</p>
<p>This study raises further questions which could inform epidemic forecast modellers and users. We recommend using the dataset created by the European Forecast Hub for further research on forecast performance. Future work could explore the impact of changing epidemiology on individual or ensemble models by combining analyses of trends and turning points in cases and deaths with forecast performance, or extending to include data on vaccination, variant, or policy changes over time. There is also a wide range of methods for combining forecasts which could improve performance of an ensemble or continue to demonstrate the value of a simple approach. This includes altering the inclusion criteria of forecast models based on different thresholds of past performance, excluding or including only forecasts that predict the lowest- and highest-values (trimming) <span class="citation">[@taylorCombiningProbabilisticForecasts2021]</span>, or using alternative weighting methods such as quantile regression averaging <span class="citation">[@funkShorttermForecastsInform2020]</span>. Exploring these questions would add to our understanding of real time performance, supporting and improving future forecasting efforts.</p>
<p>We further recommend adapting and using our open-source computational infrastructure elsewhere for applied public health work. The hub structure maximises the transparency and accuracy of real-time forecasts and can reduce reliance on individual models as a basis for action during an epidemic. The benefits of combining multiple models into an ensemble come from individual models’ wide variation in forecast performance across varying targets, and this is particularly true during emerging epidemics where forecasters vary in how quickly their models are able to adapt to new information. Setting up the infrastructure for this could be an important component to future epidemic and pandemic preparedness.</p>
<p>In conclusion, we have shown that an ensemble forecast performed reliably well across multiple forecast targets, with good short term predictions during a rapidly evolving epidemic spreading through multiple populations. However we have also demonstrated there are clear limits to predictability, especially for case forecasts longer than two weeks, with few methods able to consistently improve forecast performance other than the use of a median rather than mean average.</p>
</div>
<div id="references" class="section level1">
<h1>References</h1>
<div id="refs">

</div>
</div>
<div id="supplementary-information" class="section level1">
<h1>Supplementary information</h1>
<div class="figure" style="text-align: center">
<img src="figure/euro-hub-ensemble-draft.Rmd/si-figure-model-by-location-1.png" alt="Figure SI1: Performance of short-term forecasts across models and median ensemble (asterisk), by country, forecasting cases (left) and deaths (right) for one-week (top) through four-week (bottom) ahead forecasts, according to the relative weighted interval score. Boxplots show interquartile ranges, with outliers as faded points, and the ensemble model performance is marked by an asterisk." width="150%" />
<p class="caption">
Figure SI1: Performance of short-term forecasts across models and median ensemble (asterisk), by country, forecasting cases (left) and deaths (right) for one-week (top) through four-week (bottom) ahead forecasts, according to the relative weighted interval score. Boxplots show interquartile ranges, with outliers as faded points, and the ensemble model performance is marked by an asterisk.
</p>
</div>
<div class="figure" style="text-align: center">
<img src="figure/euro-hub-ensemble-draft.Rmd/si-figure-alternative-ensembles-1.png" alt="Figure SI2: Performance of alternative ensemble methods at each weekly horizon (1-4), showing mean difference (triangle) in relative weighted interval score, with 48% and 96% probability (thick and thin line respectively). The difference in WIS is a comparison of scores from forecasts made from all possible combinations of methods, with a single element of ensemble method input changed. Reference categories are: weighted v. unweighted; median v. mean; cutoff by WIS v. all models included;, relative WIS measures over 10 weeks of forecast history vs. all forecasts" width="672" height="30%" />
<p class="caption">
Figure SI2: Performance of alternative ensemble methods at each weekly horizon (1-4), showing mean difference (triangle) in relative weighted interval score, with 48% and 96% probability (thick and thin line respectively). The difference in WIS is a comparison of scores from forecasts made from all possible combinations of methods, with a single element of ensemble method input changed. Reference categories are: weighted v. unweighted; median v. mean; cutoff by WIS v. all models included;, relative WIS measures over 10 weeks of forecast history vs. all forecasts
</p>
</div>
<br>
<p>
<button type="button" class="btn btn-default btn-workflowr btn-workflowr-sessioninfo" data-toggle="collapse" data-target="#workflowr-sessioninfo" style="display: block;">
<span class="glyphicon glyphicon-wrench" aria-hidden="true"></span> Session information
</button>
</p>
<div id="workflowr-sessioninfo" class="collapse">
<pre><code>R version 4.0.4 (2021-02-15)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows 10 x64 (build 22000)

Matrix products: default

locale:
[1] LC_COLLATE=English_United Kingdom.1252 
[2] LC_CTYPE=English_United Kingdom.1252   
[3] LC_MONETARY=English_United Kingdom.1252
[4] LC_NUMERIC=C                           
[5] LC_TIME=English_United Kingdom.1252    

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
 [1] covidHubUtils_0.1.6 readr_2.1.0         gghighlight_0.3.2  
 [4] patchwork_1.1.1     forcats_0.5.1       ggplot2_3.3.5      
 [7] purrr_0.3.4         lubridate_1.8.0     tidyr_1.1.4        
[10] dplyr_1.0.7         here_1.0.1          workflowr_1.6.2    

loaded via a namespace (and not attached):
 [1] Rcpp_1.0.7         assertthat_0.2.1   rprojroot_2.0.2    digest_0.6.28     
 [5] foreach_1.5.1      utf8_1.2.2         R6_2.5.1           evaluate_0.14     
 [9] highr_0.9          httr_1.4.2         pillar_1.6.4       rlang_0.4.11      
[13] rstudioapi_0.13    whisker_0.4        jquerylib_0.1.4    rmarkdown_2.11    
[17] labeling_0.4.2     stringr_1.4.0      bit_4.0.4          munsell_0.5.0     
[21] compiler_4.0.4     httpuv_1.6.3       xfun_0.28          pkgconfig_2.0.3   
[25] htmltools_0.5.2    tidyselect_1.1.1   tibble_3.1.6       codetools_0.2-18  
[29] fansi_0.5.0        crayon_1.4.2       tzdb_0.2.0         withr_2.4.2       
[33] later_1.3.0        grid_4.0.4         jsonlite_1.7.2     gtable_0.3.0      
[37] lifecycle_1.0.1    DBI_1.1.1          git2r_0.29.0       magrittr_2.0.1    
[41] scales_1.1.1       cli_3.1.0          stringi_1.7.5      vroom_1.5.6       
[45] farver_2.1.0       fs_1.5.0           promises_1.2.0.1   doParallel_1.0.16 
[49] bslib_0.3.1        ellipsis_0.3.2     generics_0.1.1     vctrs_0.3.8       
[53] RColorBrewer_1.1-2 iterators_1.0.13   tools_4.0.4        bit64_4.0.5       
[57] glue_1.5.0         hms_1.1.1          parallel_4.0.4     fastmap_1.1.0     
[61] yaml_2.2.1         colorspace_2.0-2   knitr_1.36         sass_0.4.0        </code></pre>
</div>
</div>


<!-- Adjust MathJax settings so that all math formulae are shown using
TeX fonts only; see
http://docs.mathjax.org/en/latest/configuration.html.  This will make
the presentation more consistent at the cost of the webpage sometimes
taking slightly longer to load. Note that this only works because the
footer is added to webpages before the MathJax javascript. -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    "HTML-CSS": { availableFonts: ["TeX"] }
  });
</script>




</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->

<script>
$(document).ready(function ()  {

    // temporarily add toc-ignore selector to headers for the consistency with Pandoc
    $('.unlisted.unnumbered').addClass('toc-ignore')

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_');
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
